import pandas as pd
import os

def run():
    # Ruta del archivo original
    input_path = r"C:\Users\yanin\OneDrive\Desktop\proyecto final\archivos\yelp\checkin.json"

    # Ruta del archivo de salida
    output_dir = r"C:\Users\yanin\OneDrive\Desktop\etl\data_lake\clean\yelp"
    os.makedirs(output_dir, exist_ok=True)
    output_file = os.path.join(output_dir, "checkins.parquet")

    # ğŸ“¥ Cargar el archivo JSON
    df_checkins = pd.read_json(input_path, lines=True)

    # ğŸ“‹ InformaciÃ³n general
    print("ğŸ“Š Primeras filas:")
    print(df_checkins.head())
    print("\nğŸ“Š InformaciÃ³n del DataFrame:")
    print(df_checkins.info())
    print("\nğŸ“Š Tipos de datos:")
    print(df_checkins.dtypes)
    print(f"\nğŸ“ TamaÃ±o: {df_checkins.shape}")
    print("\nğŸ§¼ Nulos por columna:")
    print(df_checkins.isnull().sum())
    print(f"\nğŸ” Filas duplicadas: {df_checkins.duplicated().sum()}")

    # Mostrar duplicados si existen
    df_duplicados = df_checkins[df_checkins.duplicated()]
    if not df_duplicados.empty:
        print("\nğŸ” Duplicados encontrados:")
        print(df_duplicados)

    # ğŸ“ˆ EstadÃ­sticas generales
    print("\nğŸ“ˆ EstadÃ­sticas:")
    print(df_checkins.describe(include="all"))

    # ğŸ› ï¸ NormalizaciÃ³n de fechas separadas por coma
    rows = []
    for entry in df_checkins.to_dict(orient="records"):
        business_id = entry["business_id"]
        if pd.notna(entry["date"]):
            dates = entry["date"].split(", ")
            for date in dates:
                rows.append({"business_id": business_id, "checkin_date": date})

    # ğŸ§¾ Crear DataFrame limpio
    df_checkin = pd.DataFrame(rows)

    # ğŸ’¾ Guardar como Parquet
    df_checkin.to_parquet(output_file, engine="pyarrow", compression="snappy")

    print(f"\nâœ… Archivo guardado correctamente en: {output_file}")
    print(f"ğŸ“ Dimensiones finales: {df_checkin.shape}")
